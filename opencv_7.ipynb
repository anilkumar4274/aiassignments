{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "opencv_7.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilkumar4274/aiassignments/blob/sharath/opencv_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNA86yJIKFQX",
        "colab_type": "text"
      },
      "source": [
        "Cascade classifier - Haar Cascades\n",
        "\n",
        "Scale Invariant Feature Transformation - (SIFT)\n",
        "\n",
        "Speed-Up robust features - (SURF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhz4kqDUKFQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 #importing cv2 library\n",
        "cam = cv2.VideoCapture(0) #capture live laptop webcam\n",
        "while (cam.isOpened()):\n",
        "    ret, frame = cam.read()\n",
        "    cv2.imshow('frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pksV4bEsKFQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 #importing cv2 library\n",
        "cam = cv2.VideoCapture(\"C:\\\\Users\\\\anil\\\\Desktop\\\\Most Popular Programming Languages on Stack Overflow Bar Chart Race.mp4\") #capture live laptop webcam\n",
        "while (cam.isOpened()):\n",
        "    ret, frame = cam.read()\n",
        "    cv2.imshow('frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqCjkYtKFQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "cam = cv2.VideoCapture(\"C:\\\\Users\\\\anil\\\\Desktop\\\\Most Popular Programming Languages on Stack Overflow Bar Chart Race.mp4\") #capture live laptop webcam\n",
        "cam.set(cv2.CAP_PROP_POS_FRAMES, 100) # This will set the start point to frame 1800\n",
        "while (cam.isOpened()):\n",
        "    ret, frame = cam.read()\n",
        "    cv2.imshow('frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ri51EZ4KFQr",
        "colab_type": "code",
        "colab": {},
        "outputId": "6e0ebad7-f7fe-4d47-dbb3-44c66a7b4a09"
      },
      "source": [
        "import cv2\n",
        "cam = cv2.VideoCapture(0)\n",
        "ret, frame = cam.read()\n",
        "frame.shape[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 640, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlSqiMzjKFRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "cam = cv2.VideoCapture(0)\n",
        "ret, frame = cam.read()\n",
        "h, w = frame.shape[:2]\n",
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "video_write = cv2.VideoWriter('saved_out.avi', fourcc, 25.0, (w, h) )\n",
        "while (cam.isOpened()):\n",
        "    ret, frame = cam.read()\n",
        "    video_write.write(frame)\n",
        "    cv2.imshow('video',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cam.release()\n",
        "video_write.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XAfGnXeKFRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "cam = cv2.VideoCapture(0)\n",
        "while (cam.isOpened()):\n",
        "    ret, frame = cam.read()\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.imshow('gray_frame',gray_frame)\n",
        "    cv2.imshow('original_frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEjfFcmUKFRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "def detect(img):\n",
        "    lower_range = np.array([40,150,150], dtype = \"uint8\")\n",
        "    upper_range = np.array([70,255,255], dtype = \"uint8\")\n",
        "    img = cv2.inRange(img,lower_range,upper_range)\n",
        "    cv2.imshow(\"Range\",img)\n",
        "    m=cv2.moments(img)\n",
        "    if (m[\"m00\"] != 0):\n",
        "        x = int(m[\"m10\"]/m[\"m00\"])\n",
        "        y = int(m[\"m01\"]/m[\"m00\"])\n",
        "    else:\n",
        "        x = 0\n",
        "        y = 0\n",
        "    return (x, y)\n",
        "cam = cv2.VideoCapture(0)\n",
        "last_x = 0\n",
        "last_y = 0\n",
        "while (cam.isOpened()):\n",
        "    ret, frame = cam.read()\n",
        "    cur_x, cur_y = detect(frame)\n",
        "    cv2.line(frame,(cur_x,cur_y),(last_x,last_y),(0,0,200),5);\n",
        "    last_x = cur_x\n",
        "    last_y = cur_y\n",
        "    cv2.imshow('frame',frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtK7FtILKFR-",
        "colab_type": "text"
      },
      "source": [
        "# Opticalflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll_Rj5VHKFR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict( maxCorners = 1000,\n",
        "                       qualityLevel = 0.3,\n",
        "                       minDistance = 7,\n",
        "                       blockSize = 5,\n",
        "                       useHarrisDetector=1,\n",
        "                       k=0.04)\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict( winSize  = (15,15),\n",
        "                  maxLevel = 2)\n",
        "\n",
        "# Create some random colors\n",
        "color = np.random.randint(0,255,(1000,3))\n",
        "\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "count = 0 #To keep track of how many frames have been read\n",
        "\n",
        "while(1):\n",
        "    ret,frame = cap.read()\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    # calculate optical flow\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "    # Select good points\n",
        "    good_new = p1[st==1]\n",
        "    good_old = p0[st==1]\n",
        "    # draw the tracks\n",
        "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
        "        a,b = new.ravel()\n",
        "        c,d = old.ravel()\n",
        "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
        "    img = cv2.add(frame,mask)\n",
        "    cv2.imshow('frame',img)\n",
        "    k = cv2.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    #Recompute the goodFeaturesToTrack as the scene may have changed drastically\n",
        "    count = count + 1\n",
        "    if count % 100 == 0:\n",
        "        p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
        "    else:\n",
        "        p0 = good_new.reshape(-1,1,2)\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN2Pu-OzKFSF",
        "colab_type": "text"
      },
      "source": [
        "BOOSTING Tracker: Based on the same algorithm used to power the machine learning behind Haar cascades (AdaBoost), but like Haar cascades, is over a decade old. This tracker is slow and doesn’t work very well. Interesting only for legacy reasons and comparing other algorithms. \n",
        "\n",
        "MIL Tracker: Better accuracy than BOOSTING tracker but does a poor job of reporting failure. \n",
        "\n",
        "KCF Tracker: Kernelized Correlation Filters. Faster than BOOSTING and MIL. Similar to MIL and KCF, does not handle full occlusion well. \n",
        "\n",
        "CSRT Tracker: Discriminative Correlation Filter (with Channel and Spatial Reliability). Tends to be more accurate than KCF but slightly slower. \n",
        "\n",
        "MedianFlow Tracker: Does a nice job reporting failures; however, if there is too large of a jump in motion, such as fast moving objects, or objects that change quickly in their appearance, the model will fail. \n",
        "\n",
        "TLD Tracker: I’m not sure if there is a problem with the OpenCV implementation of the TLD tracker or the actual algorithm itself, but the TLD tracker was incredibly prone to false-positives. I do not recommend using this OpenCV object tracker.\n",
        "\n",
        "MOSSE Tracker: Very, very fast. Not as accurate as CSRT or KCF but a good choice if you need pure speed. \n",
        "\n",
        "GOTURN Tracker: The only deep learning-based object detector included in OpenCV. It requires additional model files to run (will not be covered in this post). My initial experiments showed it was a bit of a pain to use even though it reportedly handles viewing changes well (my initial experiments didn’t confirm this though). I’ll try to cover it in a future post, but in the meantime, take a look at Satya’s writeup. "
      ]
    }
  ]
}